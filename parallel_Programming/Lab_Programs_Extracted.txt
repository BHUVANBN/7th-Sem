Program 1: Write an OpenMP program to sort an array of n elements using both sequential and parallel merge sort (using sections). Record the difference in execution time.
#include <stdio.h>
#include <stdlib.h>
#include <omp.h>
#include <time.h>

#define SIZE 100000

void merge(int arr[], int left, int mid, int right) {
    int n1 = mid - left + 1;
    int n2 = right - mid;
    int *L = (int *)malloc(n1 * sizeof(int));
    int *R = (int *)malloc(n2 * sizeof(int));
    for (int i = 0; i < n1; i++) L[i] = arr[left + i];
    for (int j = 0; j < n2; j++) R[j] = arr[mid + 1 + j];
    int i = 0, j = 0, k = left;
    while (i < n1 && j < n2)
        arr[k++] = (L[i] <= R[j]) ? L[i++] : R[j++];
    while (i < n1) arr[k++] = L[i++];
    while (j < n2) arr[k++] = R[j++];
    free(L); free(R);
}

void serialMergeSort(int arr[], int left, int right) {
    if (left < right) {
        int mid = left + (right - left) / 2;
        serialMergeSort(arr, left, mid);
        serialMergeSort(arr, mid + 1, right);
        merge(arr, left, mid, right);
    }
}

void parallelMergeSort(int arr[], int left, int right, int depth) {
    if (left < right) {
        int mid = left + (right - left) / 2;
        if (depth <= 3) {
            #pragma omp parallel sections
            {
                #pragma omp section
                parallelMergeSort(arr, left, mid, depth + 1);
                #pragma omp section
                parallelMergeSort(arr, mid + 1, right, depth + 1);
            }
        } else {
            serialMergeSort(arr, left, mid);
            serialMergeSort(arr, mid + 1, right);
        }
        merge(arr, left, mid, right);
    }
}

int main() {
    int *arr_serial = (int *)malloc(SIZE * sizeof(int));
    int *arr_parallel = (int *)malloc(SIZE * sizeof(int));
    if (!arr_serial || !arr_parallel) return 1;

    srand(42);
    for (int i = 0; i < SIZE; i++) {
        int val = rand() % 100000;
        arr_serial[i] = val;
        arr_parallel[i] = val;
    }

    clock_t start_serial = clock();
    serialMergeSort(arr_serial, 0, SIZE - 1);
    clock_t end_serial = clock();
    double time_serial = (double)(end_serial - start_serial) / CLOCKS_PER_SEC;

    clock_t start_parallel = clock();
    parallelMergeSort(arr_parallel, 0, SIZE - 1, 0);
    clock_t end_parallel = clock();
    double time_parallel = (double)(end_parallel - start_parallel) / CLOCKS_PER_SEC;

    printf("Serial Merge Sort Time   : %.6f seconds\n", time_serial);
    printf("Parallel Merge Sort Time : %.6f seconds\n", time_parallel);

    for (int i = 0; i < SIZE; i++) {
        if (arr_serial[i] != arr_parallel[i]) {
            printf("Mismatch at index %d\n", i);
            break;
        }
    }

    free(arr_serial);
    free(arr_parallel);
    return 0;
}

Program 2: Write an OpenMP program that divides the iterations into chunks containing 2 iterations (OMP_SCHEDULE=static,2). Its input should be the number of iterations, and its output should be which iterations of a parallelized for loop are executed by which thread.
#include <stdio.h>
#include <omp.h>

int main() {
    int n, thread;
    printf("Enter the number of tasks: ");
    if (scanf("%d", &n) != 1) return 1;
    printf("Enter the number of threads: ");
    if (scanf("%d", &thread) != 1) return 1;

    omp_set_num_threads(thread);
    printf("--------------------------------------\n");

    #pragma omp parallel for schedule(static, 2)
    for (int i = 0; i < n; i++) {
        printf("Thread %d executes iteration %d\n", omp_get_thread_num(), i);
    }
    return 0;
}
// Compile with:
gcc -fopenmp p2.c -o p2


Program 3: Write an OpenMP program to calculate n-th Fibonacci number using tasks, and also compute it serially to compare times.
#include <stdio.h>
#include <omp.h>
#include <time.h>

long long ser_fib(long long n) {
    if (n < 2) return n;
    return ser_fib(n - 1) + ser_fib(n - 2);
}

long long fib(long long n) {
    if (n < 2) return n;
    long long x, y;
    #pragma omp task shared(x)
    x = fib(n - 1);
    #pragma omp task shared(y)
    y = fib(n - 2);
    #pragma omp taskwait
    return x + y;
}

int main() {
    long long n, result;
    clock_t start, end;
    double cpu_time;

    printf("Enter the value of n: ");
    if (scanf("%lld", &n) != 1) return 1;

    start = clock();
    #pragma omp parallel
    {
        #pragma omp single
        result = fib(n);
    }
    end = clock();
    cpu_time = (double)(end - start) / CLOCKS_PER_SEC;
    printf("Fibonacci(%lld) = %lld\n", n, result);
    printf("Time (parallel tasks) = %f seconds\n", cpu_time);

    start = clock();
    result = ser_fib(n);
    end = clock();
    cpu_time = (double)(end - start) / CLOCKS_PER_SEC;
    printf("Fibonacci(%lld) = %lld\n", n, result);
    printf("Time (serial) = %f seconds\n", cpu_time);

    return 0;
}

Program 4: Write an OpenMP program to find the prime numbers from 1 to n employing the parallel for directive. Record both serial and parallel execution times.
#include <stdio.h>
#include <omp.h>
#include <time.h>

int is_prime(long n) {
    if (n < 2) return 0;
    for (long i = 2; i * i <= n; i++)
        if (n % i == 0) return 0;
    return 1;
}

int main() {
    long n;
    clock_t start, end;
    double cpu_time;

    printf("Enter n (upper bound): ");
    if (scanf("%ld", &n) != 1) return 1;
    printf("The range of numbers is 1 to %ld\n", n);
    printf("---------------------------------\n");

    start = clock();
    for (long i = 1; i <= n; i++) {
        (void)is_prime(i);
    }
    end = clock();
    cpu_time = (double)(end - start) / CLOCKS_PER_SEC;
    printf("Time to compute prime numbers serially: %f\n", cpu_time);

    start = clock();
    #pragma omp parallel for
    for (long i = 1; i <= n; i++) {
        (void)is_prime(i);
    }
    end = clock();
    cpu_time = (double)(end - start) / CLOCKS_PER_SEC;
    printf("Time to compute prime numbers parallel: %f\n", cpu_time);

    return 0;
}

Program 5: Write an MPI program demonstrating MPI_Send and MPI_Recv.
#include <stdio.h>
#include <mpi.h>

int main(int argc, char *argv[]) {
    int rank, size;
    int number;

    MPI_Init(&argc, &argv);
    MPI_Comm_size(MPI_COMM_WORLD, &size);
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);

    if (size < 2) {
        if (rank == 0) {
            printf("This program requires at least 2 processes.\n");
        }
        MPI_Finalize();
        return 0;
    }

    if (rank == 0) {
        number = 42;
        printf("Process 0 is sending number %d to Process 1\n", number);
        MPI_Send(&number, 1, MPI_INT, 1, 0, MPI_COMM_WORLD);
    } else if (rank == 1) {
        MPI_Recv(&number, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);
        printf("Process 1 received number %d from Process 0\n", number);
    }

    MPI_Finalize();
    return 0;
}

Program 6: Write an MPI program demonstrating deadlock using point-to-point communication and avoidance of deadlock by altering the call sequence.
#include <stdio.h>
#include <string.h>
#include <mpi.h>

static void run_deadlock_demo(int rank) {
    int data_send = rank, data_recv = -1;
    if (rank == 0) {
        MPI_Ssend(&data_send, 1, MPI_INT, 1, 0, MPI_COMM_WORLD);
        MPI_Recv(&data_recv, 1, MPI_INT, 1, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);
    } else if (rank == 1) {
        MPI_Ssend(&data_send, 1, MPI_INT, 0, 0, MPI_COMM_WORLD);
        MPI_Recv(&data_recv, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);
    }
    printf("Process %d received %d\n", rank, data_recv);
}

static void run_no_deadlock_demo(int rank) {
    int data_send = rank, data_recv = -1;
    if (rank == 0) {
        MPI_Send(&data_send, 1, MPI_INT, 1, 0, MPI_COMM_WORLD);
        MPI_Recv(&data_recv, 1, MPI_INT, 1, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);
    } else if (rank == 1) {
        MPI_Recv(&data_recv, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);
        MPI_Send(&data_send, 1, MPI_INT, 0, 0, MPI_COMM_WORLD);
    }
    printf("Process %d received %d\n", rank, data_recv);
}

int main(int argc, char *argv[]) {
    int rank, size;
    MPI_Init(&argc, &argv);
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);

    if (size < 2) {
        if (rank == 0) printf("Run with at least 2 processes.\n");
        MPI_Finalize();
        return 0;
    }

    int avoid = 0;
    if (argc > 1 && strcmp(argv[1], "avoid") == 0) avoid = 1;

    if (avoid) run_no_deadlock_demo(rank);
    else run_deadlock_demo(rank);

    MPI_Finalize();
    return 0;
}

Program 7: Write an MPI program to demonstrate broadcast operation (MPI_Bcast).
#include <stdio.h>
#include <mpi.h>

int main(int argc, char **argv) {
    int rank, data = 0;
    MPI_Init(&argc, &argv);
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);

    if (rank == 0) data = 100;

    MPI_Bcast(&data, 1, MPI_INT, 0, MPI_COMM_WORLD);
    printf("Process %d received data: %d\n", rank, data);

    MPI_Finalize();
    return 0;
}

Program 8: Write an MPI program demonstrating MPI_Scatter and MPI_Gather.
#include <stdio.h>
#include <stdlib.h>
#include <mpi.h>

int main(int argc, char **argv) {
    int rank, size, recv_data;
    int *send_data = NULL;

    MPI_Init(&argc, &argv);
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);

    if (rank == 0) {
        send_data = (int *)malloc(size * sizeof(int));
        for (int i = 0; i < size; i++) send_data[i] = 10 * (i + 1);
    }

    MPI_Scatter(send_data, 1, MPI_INT, &recv_data, 1, MPI_INT, 0, MPI_COMM_WORLD);
    printf("Process %d received: %d\n", rank, recv_data);

    recv_data += 1;

    if (rank == 0) {
        for (int i = 0; i < size; i++) send_data[i] = 0;
    }

    MPI_Gather(&recv_data, 1, MPI_INT, send_data, 1, MPI_INT, 0, MPI_COMM_WORLD);

    if (rank == 0) {
        printf("Gathered data: ");
        for (int i = 0; i < size; i++) printf("%d ", send_data[i]);
        printf("\n");
        free(send_data);
    }

    MPI_Finalize();
    return 0;
}

Program 9: Write an MPI program demonstrating MPI_Reduce and MPI_Allreduce (MPI_MAX, MPI_MIN, MPI_SUM, MPI_PROD).
#include <stdio.h>
#include <mpi.h>

int main(int argc, char **argv) {
    int rank, size;
    int value, sum, prod, max, min;

    MPI_Init(&argc, &argv);
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);

    value = rank + 1;

    MPI_Reduce(&value, &sum, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);
    MPI_Reduce(&value, &prod, 1, MPI_INT, MPI_PROD, 0, MPI_COMM_WORLD);
    MPI_Allreduce(&value, &max, 1, MPI_INT, MPI_MAX, MPI_COMM_WORLD);
    MPI_Allreduce(&value, &min, 1, MPI_INT, MPI_MIN, MPI_COMM_WORLD);

    if (rank == 0) {
        printf("Sum using Reduce: %d\n", sum);
        printf("Product using Reduce: %d\n", prod);
    }
    printf("Rank %d sees Max via Allreduce: %d\n", rank, max);
    printf("Rank %d sees Min via Allreduce: %d\n", rank, min);

    MPI_Finalize();
    return 0;
}

